{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a33aca",
   "metadata": {},
   "source": [
    "# 1. Hello-world lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116368a5",
   "metadata": {},
   "source": [
    "A simple Lambda function that:\n",
    "- Reads `length` and `width` from the event.\n",
    "- Calculates the area (`length * width`).\n",
    "- Logs the result to CloudWatch.\n",
    "- Returns the area as JSON.\n",
    "\n",
    "**Example**  \n",
    "Input: `{\"length\": 5, \"width\": 3}`  \n",
    "Output: `{\"area\": 15}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    # Get the length and width parameters from the event object. The \n",
    "    # runtime converts the event object to a Python dictionary\n",
    "    length = event['length']\n",
    "    width = event['width']\n",
    "    \n",
    "    area = calculate_area(length, width)\n",
    "    print(f\"The area is {area}\")\n",
    "        \n",
    "    logger.info(f\"CloudWatch logs group: {context.log_group_name}\")\n",
    "    \n",
    "    # return the calculated area as a JSON string\n",
    "    data = {\"area\": area}\n",
    "    return json.dumps(data)\n",
    "    \n",
    "def calculate_area(length, width):\n",
    "    return length*width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f865851",
   "metadata": {},
   "source": [
    "# 2. Crypto price notifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa80f8",
   "metadata": {},
   "source": [
    "A Lambda function that:\n",
    "- Fetches the current Ethereum price in USD from the **CoinGecko API**.\n",
    "- Compares it to a predefined threshold (`THRESHOLD`).\n",
    "- If the price exceeds the threshold, sends an alert via **AWS SNS**.\n",
    "- Returns the current price in the HTTP response.\n",
    "\n",
    "**Services Used**\n",
    "- **Lambda** — executes the function.\n",
    "- **SNS** — sends price alerts.\n",
    "- **CloudWatch** — logs execution details.\n",
    "- **External API** — CoinGecko for real-time ETH price.\n",
    "\n",
    "**Example**  \n",
    "- Threshold: `$3800`  \n",
    "- Current price: `$3850` -> SNS alert is sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3289a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import boto3\n",
    "\n",
    "SNS_TOPIC_ARN = 'arn:aws:sns:REGION:ACCOUNT_ID:crypto-alerts'  # replace\n",
    "\n",
    "THRESHOLD = 3000  # ETH price USD\n",
    "CURRENCY = \"usd\"\n",
    "COIN = \"ethereum\"\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    url = f\"https://api.coingecko.com/api/v3/simple/price?ids={COIN}&vs_currencies={CURRENCY}\"\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            data = json.loads(response.read())\n",
    "            price = data[COIN][CURRENCY]\n",
    "            print(f\"Current {COIN.upper()} price: ${price}\")\n",
    "\n",
    "            if price > THRESHOLD:\n",
    "                send_alert(price)\n",
    "\n",
    "            return {\n",
    "                'statusCode': 200,\n",
    "                'body': f'ETH Price: ${price}'\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps('Error fetching price')\n",
    "        }\n",
    "\n",
    "def send_alert(price):\n",
    "    sns = boto3.client('sns')\n",
    "    message = f\"ETH price is high: ${price}!\"\n",
    "    sns.publish(\n",
    "        TopicArn=SNS_TOPIC_ARN,\n",
    "        Subject=\"ETH Price Alert\",\n",
    "        Message=message\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1aad46",
   "metadata": {},
   "source": [
    "# 3. DEX Arbitrage monitoring Lambda\n",
    "\n",
    "This AWS Lambda function monitors the price difference between two decentralized exchanges (represented here by Coinbase and Binance as stand-ins for Uniswap and Sushiswap).  \n",
    "It uses a **Z-score statistical model** to detect arbitrage opportunities and logs them to multiple destinations for further processing.\n",
    "\n",
    "The project demonstrates:\n",
    "- Event-driven Lambda design\n",
    "- AWS service integration\n",
    "- Efficient DB connection reuse in a serverless environment\n",
    "- Real-time data ingestion, statistical processing, and alerting\n",
    "\n",
    "---\n",
    "\n",
    "## AWS Services Involved\n",
    "\n",
    "| Service | Purpose |\n",
    "| ------- | ------- |\n",
    "| **AWS Lambda** | Core processing logic: fetching prices, computing Z-scores, orchestrating actions |\n",
    "| **Amazon SSM** | Stores the Z-score threshold `/arbitrage/threshold`, supports live updates without redeployment |\n",
    "| **Amazon DynamoDB** | Keeps the rolling history of recent price differences for statistical analysis |\n",
    "| **Amazon RDS (PostgreSQL)** | Persistent storage of detected arbitrage opportunities |\n",
    "| **Amazon S3** | Stores opportunity snapshots in JSON for audit & replay |\n",
    "| **Amazon SQS** | Sends opportunity messages to downstream consumers |\n",
    "| **Amazon CloudWatch** | Logs application output and publishes custom metrics |\n",
    "| **API Gateway** – Accepts POST /tick calls with custom prices and parameter updates |\n",
    "| **Amazon IAM** | Grants Lambda access to RDS, SSM, S3, DynamoDB, SQS, and CloudWatch |\n",
    "| **Amazon EventBridge** | Triggers scheduled runs and reacting to SSM parameter updates |\n",
    "| **External APIs** | Fetches ETH/USD prices from Coinbase and Binance (proxy for DEX reads) |\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture & Flow\n",
    "\n",
    "Below is a logical representation of the pipeline:This AWS Lambda function monitors the price difference between two decentralized exchanges (represented here by Coinbase and Binance as stand-ins for Uniswap and Sushiswap).  \n",
    "It uses a **Z-score statistical model** to detect arbitrage opportunities and logs them to multiple destinations for further processing.\n",
    "\n",
    "The project demonstrates:\n",
    "- Event-driven Lambda design\n",
    "- AWS service integration\n",
    "- Efficient DB connection reuse in a serverless environment\n",
    "- Real-time data ingestion, statistical processing, and alerting\n",
    "\n",
    "---\n",
    "\n",
    "## AWS Services Involved\n",
    "\n",
    "| Service | Purpose |\n",
    "| ------- | ------- |\n",
    "| **AWS Lambda** | Core processing logic: fetching prices, computing Z-scores, orchestrating actions |\n",
    "| **Amazon SSM Parameter Store** | Stores the Z-score threshold `/arbitrage/threshold`, supports live updates without redeployment |\n",
    "| **Amazon DynamoDB** | Keeps the rolling history of recent price differences for statistical analysis |\n",
    "| **Amazon RDS (PostgreSQL)** | Persistent storage of detected arbitrage opportunities |\n",
    "| **Amazon S3** | Stores opportunity snapshots in JSON for audit & replay |\n",
    "| **Amazon SQS** | Sends opportunity messages to downstream consumers |\n",
    "| **Amazon CloudWatch** | Logs application output and publishes custom metrics |\n",
    "| **External APIs** | Fetches ETH/USD prices from Coinbase and Binance (proxy for DEX reads) |\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture & Flow\n",
    "\n",
    "Below is a logical representation of the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bfb56",
   "metadata": {},
   "source": [
    "    ┌───────────────────────────────┐\n",
    "    │   Event Sources               │\n",
    "    │                               │\n",
    "    │  1. SSM Parameter Change Event│─── updates cached threshold\n",
    "    │  2. API Gateway POST /tick    │─── prices provided in request body\n",
    "    │  3. EventBridge Scheduled Run │─── fetches prices from APIs\n",
    "    └───────────────────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌───────────────────┐\n",
    "         │  Lambda Handler   │\n",
    "         └───────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌───────────────────┐\n",
    "         │  fetch_prices()   │───> Coinbase / Binance APIs\n",
    "         └───────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌─────────────────────────────┐\n",
    "         │  process_prices()           │\n",
    "         │  - Compute % diff           │\n",
    "         │  - Update DynamoDB history  │\n",
    "         │  - Compute Z-score          │\n",
    "         └─────────────────────────────┘\n",
    "                  │\n",
    "     ┌────────────┴─────────────┐\n",
    "     │ Triggered? (Z ≥ threshold)│\n",
    "     └────────────┬─────────────┘\n",
    "                  │ Yes\n",
    "                  ▼\n",
    "    ┌───────────────────────────────────────────┐\n",
    "    │ Actions                                   │\n",
    "    │                                           │\n",
    "    │  1. Store JSON in S3                      │\n",
    "    │  2. Insert row in RDS (PostgreSQL)        │\n",
    "    │  3. Send message to SQS                   │\n",
    "    │  4. Publish metric to CloudWatch          │\n",
    "    └───────────────────────────────────────────┘\n",
    "    ┌───────────────────────────────┐\n",
    "    │   Event Sources               │\n",
    "    │                               │\n",
    "    │  1. SSM Parameter Change Event│─── updates cached threshold\n",
    "    │  2. API Gateway POST /tick    │─── prices provided in request body\n",
    "    │  3. EventBridge Scheduled Run │─── fetches prices from APIs\n",
    "    └───────────────────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌───────────────────┐\n",
    "         │  Lambda Handler   │\n",
    "         └───────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌───────────────────┐\n",
    "         │  fetch_prices()   │───> Coinbase / Binance APIs\n",
    "         └───────────────────┘\n",
    "                  │\n",
    "                  ▼\n",
    "         ┌─────────────────────────────┐\n",
    "         │  process_prices()           │\n",
    "         │  - Compute % diff           │\n",
    "         │  - Update DynamoDB history  │\n",
    "         │  - Compute Z-score          │\n",
    "         └─────────────────────────────┘\n",
    "                  │\n",
    "     ┌────────────┴─────────────┐\n",
    "     │ Triggered? (Z ≥ threshold)│\n",
    "     └────────────┬─────────────┘\n",
    "                  │ Yes\n",
    "                  ▼\n",
    "    ┌───────────────────────────────────────────┐\n",
    "    │ Actions                                   │\n",
    "    │                                           │\n",
    "    │  1. Store JSON in S3                      │\n",
    "    │  2. Insert row in RDS (PostgreSQL)        │\n",
    "    │  3. Send message to SQS                   │\n",
    "    │  4. Publish metric to CloudWatch          │\n",
    "    └───────────────────────────────────────────┘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f8618",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Z-score anomaly detection**:  \n",
    "  Uses recent historical data to detect statistically significant deviations.\n",
    "  \n",
    "- **Cached parameter retrieval**:  \n",
    "  SSM Parameter Store value is cached in Lambda's execution context to minimize cold-fetch latency.\n",
    "\n",
    "- **DB connection reuse**:  \n",
    "  PostgreSQL connection is kept alive across warm invocations to improve performance.\n",
    "\n",
    "- **Multi-destination logging**:  \n",
    "  Opportunities are logged to RDS, S3, SQS, and CloudWatch for durability, analytics, and alerting.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Z-score Calculation\n",
    "\n",
    "``` diff_pct = |uni_price - sushi_price| / avg_price\n",
    "z_score = (diff_pct - mean(diff_history)) / stddev(diff_history)\n",
    "if abs(z_score) >= threshold -> trigger actions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Possible Extensions\n",
    "\n",
    "- Replace Coinbase/Binance price sources with **on-chain Uniswap/Sushiswap contract calls** using Web3.\n",
    "- Add **SNS** or **Slack webhook** for human alerts.\n",
    "- Implement **auto-trading strategy** on detected opportunities.\n",
    "- Store historical data in **Amazon Timestream** for time-series analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pg8000\n",
    "import os\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "import time\n",
    "from decimal import Decimal\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import json, urllib.request\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# AWS clients \n",
    "AWS_DEFAULT_REGION = 'eu-north-1'\n",
    "boto3.setup_default_session(region_name=AWS_DEFAULT_REGION)\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "s3 = boto3.client('s3')\n",
    "sqs = boto3.client('sqs')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "# env variables set in Lambda\n",
    "RDS_HOST = os.environ['RDS_HOST']\n",
    "RDS_DB = os.environ['RDS_DB']\n",
    "RDS_USER = os.environ['RDS_USER']\n",
    "RDS_PASS = os.environ['RDS_PASS']\n",
    "S3_BUCKET = os.environ['S3_BUCKET']\n",
    "SQS_URL = os.environ['SQS_URL']\n",
    "\n",
    "# Cached threshold values (avoid hitting SSM too often)\n",
    "_cached_threshold = None\n",
    "_cached_version = None\n",
    "_cached_expires = 0\n",
    "CACHE_TTL_SEC = 86400  # refresh once a day unless change event updates it\n",
    "\n",
    "#other constants\n",
    "MIN_HISTORY = int(os.getenv(\"MIN_HISTORY\", \"20\"))\n",
    "\n",
    "# Global RDS connection handle for reuse between Lambda invocations\n",
    "_DB_CONN = None\n",
    "\n",
    "def get_db_conn():\n",
    "    global _DB_CONN\n",
    "    if _DB_CONN:\n",
    "        try:\n",
    "            # Check if still alive\n",
    "            cur = _DB_CONN.cursor()\n",
    "            cur.execute(\"SELECT 1\")\n",
    "            cur.close()\n",
    "            return _DB_CONN\n",
    "        except Exception:\n",
    "            # If it is dead, close and reset\n",
    "            try:\n",
    "                _DB_CONN.close()\n",
    "            except:\n",
    "                pass\n",
    "            _DB_CONN = None\n",
    "    \n",
    "    # Create a new connection if not alive\n",
    "    _DB_CONN = pg8000.connect(\n",
    "        host=RDS_HOST,\n",
    "        database=RDS_DB,\n",
    "        user=RDS_USER,\n",
    "        password=RDS_PASS,\n",
    "        port=int(os.environ.get(\"RDS_PORT\", \"5432\")), \n",
    "        timeout=int(os.environ.get(\"DB_TIMEOUT\", \"15\"))\n",
    "    )\n",
    "    return _DB_CONN\n",
    "\n",
    "\n",
    "def get_z_threshold():\n",
    "    \"\"\"\n",
    "    Fetch the Z-score threshold from SSM Parameter Store.\n",
    "    Uses cached value unless expired (default: refresh every 24h).\n",
    "    \"\"\"\n",
    "    global _cached_threshold, _cached_version, _cached_expires\n",
    "    now = time.time()\n",
    "    if _cached_threshold is not None and now < _cached_expires:\n",
    "        return _cached_threshold\n",
    "\n",
    "    resp = ssm.get_parameter(Name='/arbitrage/threshold')\n",
    "    val = float(resp['Parameter']['Value'])\n",
    "    ver = resp['Parameter']['Version']\n",
    "\n",
    "    _cached_threshold = val\n",
    "    _cached_version = ver\n",
    "    _cached_expires = now + CACHE_TTL_SEC\n",
    "    return val\n",
    "\n",
    "def _http_get_json(url, timeout=3):\n",
    "    \"\"\"\n",
    "    Fetch JSON from a given URL with a custom User-Agent.\n",
    "    \"\"\"\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"price-bot/1.0\"})\n",
    "    with urllib.request.urlopen(req, timeout=timeout) as resp:\n",
    "        return json.loads(resp.read().decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def fetch_prices():\n",
    "    \"\"\"\n",
    "    Fetch ETH prices from Coinbase and Binance as stand-ins for Uniswap and Sushiswap.\n",
    "    Returns a tuple: (uniswap_price, sushiswap_price).\n",
    "    TODO: swap in on-chain reads later.\n",
    "    \"\"\"\n",
    "    # Coinbase ETH-USD\n",
    "    cb = _http_get_json(\"https://api.coinbase.com/v2/prices/ETH-USD/spot\")\n",
    "    coinbase_price = float(cb[\"data\"][\"amount\"])\n",
    "\n",
    "    # Binance ETHUSDT\n",
    "    bz = _http_get_json(\"https://api.binance.com/api/v3/ticker/price?symbol=ETHUSDT\")\n",
    "    binance_price = float(bz[\"price\"])\n",
    "\n",
    "    # Log the prices to CloudWatch\n",
    "    logger.info(f\"Fetched prices — Coinbase: {coinbase_price}, Binance: {binance_price}\")\n",
    "\n",
    "    return coinbase_price, binance_price\n",
    "\n",
    "\n",
    "def process_prices(uniswap_price, sushiswap_price, z_threshold):\n",
    "    \"\"\"\n",
    "    Main logic:\n",
    "    - Calculate % price difference between Uni and Sushi.\n",
    "    - Store history in DynamoDB.\n",
    "    - If Z-score threshold is met → log opportunity to S3, RDS, SQS, and CloudWatch.\n",
    "    \"\"\"\n",
    "    logger.info(f\"[Prices] uni={uniswap_price:.6f} sushi={sushiswap_price:.6f} threshold={z_threshold}\")\n",
    "    \n",
    "    # % difference\n",
    "    diff_pct = abs(uniswap_price - sushiswap_price) / ((uniswap_price + sushiswap_price) / 2)\n",
    "\n",
    "    # DynamoDB table\n",
    "    table = dynamodb.Table('PriceDiffHistory')\n",
    "\n",
    "    # read last 100 diffs\n",
    "    response = table.query(\n",
    "        KeyConditionExpression=Key('pk').eq('diff_history'),\n",
    "        ScanIndexForward=False,\n",
    "        Limit=100\n",
    "    )\n",
    "    diffs = [float(item[\"diff\"]) for item in response.get(\"Items\", [])]\n",
    "\n",
    "    # store current diff\n",
    "    now = datetime.utcnow().isoformat()\n",
    "    table.put_item(Item={\n",
    "        \"pk\": \"diff_history\",\n",
    "        \"timestamp\": now,\n",
    "        \"diff\": Decimal(str(diff_pct))\n",
    "    })\n",
    "\n",
    "    # Only proceed if we have enough history\n",
    "    if len(diffs) >= MIN_HISTORY:\n",
    "        mean_diff = statistics.mean(diffs)\n",
    "        std_diff = statistics.pstdev(diffs)\n",
    "        \n",
    "        if std_diff > 0:\n",
    "            z_score = (diff_pct - mean_diff) / std_diff\n",
    "            triggered = abs(z_score) >= z_threshold\n",
    "            logger.info(f\"[Z] diff={diff_pct:.6f} mean={mean_diff:.6f} std={std_diff:.6f} z={z_score:.3f} \"\n",
    "                f\"trigger={triggered}\")\n",
    "            if triggered:\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                logger.info(f\"[OPP] Logging opportunity at {timestamp}\")\n",
    "\n",
    "                opportunity = {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"uniswap\": uniswap_price,\n",
    "                    \"sushiswap\": sushiswap_price,\n",
    "                    \"diff\": diff_pct\n",
    "                }\n",
    "                # Save to S3\n",
    "                s3.put_object(\n",
    "                    Bucket=S3_BUCKET,\n",
    "                    Key=f\"arbitrage/{timestamp}.json\",\n",
    "                    Body=json.dumps(opportunity)\n",
    "                )\n",
    "\n",
    "                # Insert to RDS\n",
    "                conn = get_db_conn()\n",
    "                cur = conn.cursor()\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO opportunities (timestamp, uniswap_price, sushiswap_price, z_score, threshold, diff_pct)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", (timestamp, uniswap_price, sushiswap_price, z_score, z_threshold, diff_pct))\n",
    "                conn.commit()\n",
    "                cur.close()\n",
    "\n",
    "                # Send to SQS\n",
    "                sqs.send_message(\n",
    "                    QueueUrl=SQS_URL,\n",
    "                    MessageBody=json.dumps(opportunity)\n",
    "                )\n",
    "\n",
    "                # Publish CloudWatch metric\n",
    "                cloudwatch.put_metric_data(\n",
    "                    Namespace='DEXArbitrage',\n",
    "                    MetricData=[{\n",
    "                        'MetricName': 'ArbitrageOpportunity',\n",
    "                        'Value': diff_pct,\n",
    "                        'Unit': 'Percent'\n",
    "                    }]\n",
    "                )\n",
    "                return {\"message\": \"Opportunity logged\", \"data\": opportunity}\n",
    "    else:\n",
    "        logger.info(f\"[Z] Not enough history yet ({len(diffs)}) or std=0; skipping\")\n",
    "    return {\"message\": \"No opportunity\"}\n",
    "\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Lambda entry point:\n",
    "    - Handles SSM change events (updates threshold cache).\n",
    "    - Handles API Gateway /tick calls (body with prices).\n",
    "    - Handles scheduled calls (fetch prices directly).\n",
    "    \"\"\"\n",
    "\n",
    "    global _cached_threshold, _cached_expires  # needed when you mutate them!\n",
    "\n",
    "    # SSM parameter change event (EventBridge) -> update cache \n",
    "    if event.get('source') == 'aws.ssm':\n",
    "        detail = event.get('detail', {})\n",
    "        if detail.get('name') == '/arbitrage/threshold' and 'value' in detail:\n",
    "            _cached_threshold = float(detail['value'])\n",
    "            _cached_expires = time.time() + CACHE_TTL_SEC\n",
    "            logger.info(f\"Threshold cache updated to {_cached_threshold}\")\n",
    "            return {'statusCode': 200, 'body': json.dumps({'message': 'Threshold cache updated'})}\n",
    "\n",
    "    # SSM parameter change → update cache\n",
    "    z_threshold = get_z_threshold()\n",
    "\n",
    "    # Handle different invocation sources\n",
    "    body = None\n",
    "    if isinstance(event, dict):\n",
    "\n",
    "        # API Gateway JSON body\n",
    "        if 'body' in event and event['body']:\n",
    "            try:\n",
    "                body = json.loads(event['body'])\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Direct Lambda invoke with prices\n",
    "        if not body and 'uniswap' in event and 'sushiswap' in event:\n",
    "            body = {'uniswap': event['uniswap'], 'sushiswap': event['sushiswap']}\n",
    "\n",
    "    if body and 'uniswap' in body and 'sushiswap' in body:\n",
    "        uniswap_price = float(body['uniswap'])\n",
    "        sushiswap_price = float(body['sushiswap'])\n",
    "    else:\n",
    "        # Scheduled run (EventBridge) -> fetch our own prices\n",
    "        uniswap_price, sushiswap_price = fetch_prices()\n",
    "        \n",
    "    # Process and return result\n",
    "    result = process_prices(uniswap_price, sushiswap_price, z_threshold)\n",
    "    return {'statusCode': 200, 'body': json.dumps(result)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
